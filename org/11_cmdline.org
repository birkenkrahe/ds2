#+TITLE:Data science on the command line - Introduction
#+AUTHOR:Marcus Birkenkrahe
#+SUBTITLE:Introduction to advanced data science
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:bash :exports both :results output
#+PROPERTY: header-args:sh :exports both :results output
* README
#+attr_latex: :width 400px
#+caption: Photo: Super Hornet. Source: Flickr.com flic.kr/p/2nDe28b
[[../img/11_hornet.jpg]]

Short introduction to doing data science on the command line:
- What is the command line?
- Why use the command line for data science?
- How to get a command line that works for data science?
- Downloading data with ~curl~ and ~wget~
- Cleaning data on the command line
- Database operations on the command line
- Introduction to the ~csvkit~ toolkit (Python)
- Introduction to the ~xsv~ toolkit (Rust)
- Practice with Linux (DataCamp workspaces)

Open a fresh .org file to code along now.

* Workflow: expectation vs. reality
#+attr_html: :width 500px
#+caption: Data science pipeline (Janssen, 2021)
[[../img/11_pipeline.png]]

This is essentially our well-known data science pipeline:
#+begin_example sh
  data + code + stats = story
#+end_example
Command line example[fn:1]: what is data, code, stats and story?
#+attr_html: :width 500px
#+caption: Screenshot: Ubuntu (Windows WSL2) ps -ax --forest command
[[../img/11_psaxforest.png]]
#+begin_quote
- Data: ~PID~, ~TTY~, ~TIME~, ~COMMAND~
- Code: ~ps -ax --forest~
- Stats: snapshot of currently active CPU processes
- Story: tell me what you're busy with including dependencies!
#+end_quote

* What is the command line?

- The command line is a programming and management interface

- It consists of many thousands of programs and packages focused on
  file and process management

- Some alternative names (though not exactly the same thing):
  + Shell
  + ~bash~, ~csh~, ~sh~, ~zsh~, ~ksh~
  + eshell
  + CMD prompt (Windows), PowerShell
  + Terminal
  + tty
  #+begin_quote
  | TERM      | MEANING                      |
  |-----------+------------------------------|
  | Shell     | Program interface to the OS  |
  | ~bash~ etc. | Shell scripting languages    |
  | eshell    | Emacs bash emulator          |
  | CMD line  | Windows term for the shell   |
  | Terminal  | MacOS term for the shell     |
  | tty       | Tele-type/session management |
  |           |                              |
  #+end_quote
* Things to do on the command line
#+attr_html: :width 500px
#+caption: Things to do on the command line (Source: Janssens, 2021)
[[../img/11_cmdline.png]]

- Example in a Linux docker container:
  #+attr_html: :width 500px
  #+caption: Command line terminal (bash) in a docker container
  [[../img/11_bash.png]]

- The command line is bigger than the shell:
  | CMD LINE TOOL      | EXAMPLE         |
  |--------------------+-----------------|
  | Binary executable  | ~bash --help~     |
  | Shell builtin      | ~cd .~            |
  | Interpreted script | ~hello.sh~        |
  | Shell function     | ~pwd~, ~date~, ~echo~   |
  | Alias              | ~alias~           |

* Why use the command line for data science
#+attr_html: :width 500px
#+caption: Huskies pulling sledge (State Lib of NSW on Flickr.com)
[[../img/11_huskies.jpg]]

1. Program to interact with the *operating system* (kernel) + memory
2. Sophisticated *script* language (~bash~, ~zsh~)
3. *REPL* (Read-Eval-Print-Loop) like ~replit.com~, ~Python~, ~R~, ~SQLite~[fn:2]
4. *Agile*, flexible and exploratory
5. *Augmenting* technology (glue to other applications)
   - Run pipeline (e.g. ~ls -a | wc -l~)
   - Run from inside your R program (with ~shell~)
   - Convert R code to command line script:
     #+begin_src sh :results output
       echo 'head(mtcars)' > t.R
       cat t.R
       Rscript t.R
     #+end_src
6. *Scalability*:
   - it's fast (sits right on top of the engine)
   - it is used to automate tasks
   - repeatable and parallelizable
7. *Extensibility*:
   - language agnostic
   - been in use for a long time
   - it is continuously improved
8. *Ubiquitous*: comes with all OS
9. *Cool factor* (you're "hacking")
10. *Relatable* (logical approach)

All of these are especially valuable in an exploratory environment
with highly distributed, unstructured, or "dirty" data sources.

* How to get a commandline for data science
#+attr_html: :width 500px
#+caption: Huskies pulling sledge (State Lib of NSW on Flickr.com)
[[../img/11_workspace.png]]

We're going to use DataCamp's workspaces - the Jupyter Notebook
installation, which is free for you, includes a suitably equipped
shell ([[https://app.datacamp.com/workspace/w/7927d795-69d1-41a7-a076-76acf8c79068/edit][example]]).

*How to do it:*
1) Go to ~workspace.datacamp.com~
2) Start from ~empty [Python] workspace~
3) Enter workspace name "commandline"
4) Choose Language: "R + SQL"
5) In the notebook go to "Launcher"
6) In ~notebook.ipynb~ type ~version~ and run it
7) In ~notebook.ipynb~ type ~plot(rnorm(1000))~ and run it
8) Open another window ("+" tab) and launch "Terminal"
9) In terminal, type ~cat /etc/os-release~
10) In terminal, type ~echo 'hello world'~
11) Open an R console, type ~plot(rnorm(1000))~ and run with ~<S-RET>~
12) Open an R script, enter ~plot(rnorm(1000))~ and name it ~plot.r~
13) Run script in the console with ~Rscript plot.r~

More: [[https://support.datacamp.com/hc/en-us/articles/4680790331287-Getting-Started-with-DataCamp-Workspace][Getting Started with DataCamp Workspace]] (DataCamp 2023)

* Alternative command line installations

*Alternatives:*
- Install a Docker container as described [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#how-to-set-up-a-docker-container-for-command-line-work][in this FAQ]] - there is also
  a short explanation what a "docker container" is [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#what-is-a-docker-container][in the FAQ]].
- Install the Ubuntu app using Windows Subsystem Linux (WSL) as
  [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#how-can-i-install-linux-under-windows-10][described in this FAQ]].
- Get Linux as a dual boot or with (free) VirtualBox (any
  distro). [[https://www.howtogeek.com/796988/how-to-install-linux-in-virtualbox/][Instructions are here]]. Only for high-end laptops.
- Get a Linux computer ([[https://vilros.com/products/raspberry-pi-400-kit][like this one for $100]]) or brazenly and boldly
  just dump Windows for Linux and install it over Windows.
- Online/cloud installations like Google cloud shell, or replit.com,
  or the bundle of UNIX commands contained in ~cygwin~ do unfortunately
  not allow you to install the ~csvkit~ library, and exclude some other
  commands (like ~wget~).
- The Docker container already comes with ~cvskit~. Once you've got
  another Linux variant, install ~cvskit~ from the command line, e.g. in
  Debian-based systems (Raspberry Pi OS, Ubuntu) with the command ~sudo
  apt install csvkit~.

* Unix-type commands

- The following sections on ~curl~ and ~wget~ is based on the first
  chapter of the DataCamp course "Data processing in shell".

- Both commands obey the same Unix-type format:
  #+begin_example sh
    [command] [options/flags] [targets]
  #+end_example

- The specialty of Unix utilities are stable, small, fast routines
  each of which does one particular job really well and allow managing
  files, shell and text: e.g. ~ls~, ~ps~, ~cd~ - all of them written in C.

- The utilities attain full power only when used as part of a command
  pipeline, e.g. in the following codeblock:
  1) list files in ~$PWD~ in long format, time-ordered with ~ls~
  2) in the list, search for the pattern 'text' with ~grep~
  3) save the result of the search to a file ~files.txt~ with ~tee~
  4) count the characters of the search result with ~wc~
  #+begin_src sh
    ls -lt $PWD | grep text | tee files.txt | wc -c
    cat files.txt
  #+end_src

- The bulk of these utilities are part of the [[https://www.gnu.org/gnu/gnu.html][GNU Operating System]],
  which is FOSS. The GNU system also includes very large, complex
  programs like ~gcc~ and ~gdb~, the GNU compiler and debugger, or GNU
  Emacs, the self-extensible editor.

- Making these programs graphical does not add anything but only takes
  away transparency, speed of use, and performance - they embody the
  power of the command line.

- Jobs that cannot live without commandline tools include anything
  with data (at the engineering end), databases, networks or operating
  systems (including servers).

* Download data with ~curl~

- Open your workspace on ~workspace.datacamp.com~ to try this yourself
  or run the commands in Emacs using my practice file[fn:3]

- The ~curl~ command line tool is short for "Client for URLs" and
  transports data to and from web servers.

* Getting to know a utility

- Your first step is to look at its option palette with ~--help~:
  #+begin_src sh
    curl --help
  #+end_src

  #+RESULTS:
  #+begin_example
  Usage: curl [options...] <url>
   -d, --data <data>          HTTP POST data
   -f, --fail                 Fail fast with no output on HTTP errors
   -h, --help <category>      Get help for commands
   -i, --include              Include protocol response headers in the output
   -o, --output <file>        Write to file instead of stdout
   -O, --remote-name          Write output to a file named as the remote file
   -s, --silent               Silent mode
   -T, --upload-file <file>   Transfer local FILE to destination
   -u, --user <user:password> Server user and password
   -A, --user-agent <name>    Send User-Agent <name> to server
   -v, --verbose              Make the operation more talkative
   -V, --version              Show version number and quit

  This is not the full help, this menu is stripped into categories.
  Use "--help category" to get an overview of all categories.
  For all options use the manual or "--help all".
  #+end_example

- The help reveals that there are two sets of options/flags: a short
  version and a long, verbose version, e.g. ~-V~ and ~--version~:
  #+begin_src sh
    curl --version
  #+end_src

  #+RESULTS:
  : curl 7.88.1 (x86_64-w64-mingw32) libcurl/7.88.1 OpenSSL/1.1.1t (Schannel) zlib/1.2.13 brotli/1.0.9 zstd/1.5.4 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.10.0 nghttp2/1.52.0
  : Release-Date: 2023-02-20
  : Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp
  : Features: alt-svc AsynchDNS brotli HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz MultiSSL NTLM PSL SPNEGO SSL SSPI threadsafe TLS-SRP UnixSockets zstd

- This gives a lot of different information:
  1) version number and release date
  2) compiler and libraries used to create the binary (which is what
     you usually use under Windows, instead of building it from source
     under Linux)
  3) supported server protocols (everything under the sun)
  4) additional features to deal with network/data specifics

- Information on any shell utility is on its [[https://man7.org/linux/man-pages/man1/curl.1.html][manual page]] - on Linux,
  you can find these inside Emacs, too (~M-x man~).
  #+attr_latex: :width 400px
  #+caption: curl(7) man page
  [[../img/11_man_curl.png]]

* Examples for ~curl~

- Copy data from URL without changing name, then list file:
  #+begin_src sh
    pwd
    curl -O 'https://bit.ly/nile_txt'
    ls -l 'nile_txt'
  #+end_src

  #+RESULTS:
  : /c/Users/birkenkrahe/Documents/GitHub/ds2/org
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:14 nile_txt

- Copy data from URL, change name, then list files:
  #+begin_src sh
    pwd
    curl -o 'nile.txt' 'https://bit.ly/nile_txt'
    ls -l nile*
  #+end_src

  #+RESULTS:
  : /c/Users/birkenkrahe/Documents/GitHub/ds2/org
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:16 nile.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:14 nile_txt

- Here, the 'wildcard' or 'glob' character ~*~ is actually a regular
  expression or a - more about these in the next lecture!

- The 'globbing parser' is a shell component that interprets and
  expands globs or wildcards. Here is an example with ~curl~:
  #+begin_src sh :noweb yes
    github=https://raw.githubusercontent.com/birkenkrahe/ds2/main
    curl --remote-name "$github/data/Nile[001-003].txt"
    ls -l Nile*
  #+end_src

  #+RESULTS:
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile001.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile002.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile003.txt

- Explore other ~curl~ flags on your own time!

* Download data with ~wget~ - the background

- The utility ~wget~ is a "non-interactive" ("batch") network downloader
  that downloads very efficiently in the background from the Web.

- It is better than ~curl~ at downloading multiple files recursively
  (i.e. entering and copying nested file hierarchies), especially when
  connections are wonky - ~wget~ will just keep trying!

- Like other batch programs, ~wget~ also creates a log file ~wget-log~

- The notion of "background" relates to Unix' process management:
  e.g. I can put Emacs in the background (~C-z~) then check that the
  process is running (~ps -ax~) and bring it back into the foreground
  with ~fg~:
  #+attr_latex: :width 400px
  #+caption: Emacs in the background
  [[../img/11_background.png]]

- This is the same thing that happens when we run an R script ~file.R~
  in "batch" mode with ~R CMD BATCH file.R~: the file is executed in the
  background and an ~.Rout~ log file is produced alongside the output:
  1) download ~$github/src/t.R~ with ~curl~ and name it ~mtcars.R~
  2) check that the file is there with ~ls~
  3) look at ~mtcars.R~ with ~cat~
  4) run ~mtcars.R~ as a batch script
  5) look at ~mtcars.Rout~
  #+begin_src sh
    github=https://raw.githubusercontent.com/birkenkrahe/ds2/main
    curl -o mtcars.R "$github/src/t.R"
    ls -l mtcars.R
    cat mtcars.R
    R CMD BATCH mtcars.R
    cat mtcars.Rout
  #+end_src

* IN PROGRESS Examples with ~wget~

- Important flags:
  1) ~-b~ to go to background immediately after startup
  2) ~-q~ turn off output
  3) ~-c~ resume broken (partial) download
  4) ~-i~ pass a file with URLs to ~wget~ for download
  5) ~--limit-rate={rate}k~ set download constraint for large files
  6) ~--wait={seconds}~ pause between file downloads

* ~curl~ vs ~wget~

| ~curl~                      | ~wget~                          |
|---------------------------+-------------------------------|
| many transfer protocols   | multiple file downloads       |
| easy to install across OS | handles multiple file formats |

* TODO Summary
* TODO Code glossary
* References

- Ballesteros (2006). Introduction to Operating Systems Abstractions:
  Using Plan 9 from Bell Labs (PDF). URL: [[http://doc.cat-v.org/plan_9/9.intro.pdf][doc.cat-v.org]].
- Gallant (2021). xsv. URL: [[https://github.com/BurntSushi/xsv][github.com]].
- Janssens (2021). Data science at the command line (2e). O'Reilly.

* Footnotes

[fn:3]If these commands work on the shell in Emacs or in ~sh~ code
blocks depends on the availability of the utilities on your PC and on
your ~PATH~ environment variable settings. Alternatively you can install
Ubuntu Linux as a Windows Linux Subsystem from the Microsoft store.

[fn:2]replit.com is a platform with multiple languages set up as
REPLs. Python (~M-x run-python~), R (~M-x R~) and SQLite (~M-x sql-sqlite~)
can be run interactively.

[fn:1]Here, ~plan9~ is the weirdest kid on the block: Plan 9 is file
server also known as the 9P protocol file server. It allows Windows to
access the files contained within WSL2. The name comes from a
distributed OS called Plan 9 (see Ballesteros, 2006).
