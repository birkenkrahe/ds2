#+TITLE:Data science on the command line - Introduction
#+AUTHOR:Marcus Birkenkrahe
#+SUBTITLE:Introduction to advanced data science
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:bash :exports both :results output
#+PROPERTY: header-args:sh :exports both :results output
* README
#+attr_latex: :width 400px
#+caption: Photo: Super Hornet. Source: Flickr.com flic.kr/p/2nDe28b
[[../img/11_hornet.jpg]]

Short introduction to doing data science on the command line:
- What is the command line?
- Why use the command line for data science?
- How to get a command line that works for data science?
- Downloading data with ~curl~ and ~wget~
- Cleaning data on the command line
- Database operations on the command line
- Introduction to the ~csvkit~ toolkit (Python)
- Introduction to the ~xsv~ toolkit (Rust)
- Practice with Linux (DataCamp workspaces)

Open a fresh .org file to code along now.

* Workflow: expectation vs. reality
#+attr_html: :width 500px
#+caption: Data science pipeline (Janssen, 2021)
[[../img/11_pipeline.png]]

This is essentially our well-known data science pipeline:
#+begin_example sh
  data + code + stats = story
#+end_example
Command line example[fn:1]: what is data, code, stats and story?
#+attr_html: :width 500px
#+caption: Screenshot: Ubuntu (Windows WSL2) ps -ax --forest command
[[../img/11_psaxforest.png]]
#+begin_quote
- Data: ~PID~, ~TTY~, ~TIME~, ~COMMAND~
- Code: ~ps -ax --forest~
- Stats: snapshot of currently active CPU processes
- Story: tell me what you're busy with including dependencies!
#+end_quote

* What is the command line?

- The command line is a programming and management interface

- It consists of many thousands of programs and packages focused on
  file and process management

- Some alternative names (though not exactly the same thing):
  + Shell
  + ~bash~, ~csh~, ~sh~, ~zsh~, ~ksh~
  + eshell
  + CMD prompt (Windows), PowerShell
  + Terminal
  + tty
  #+begin_quote
  | TERM      | MEANING                      |
  |-----------+------------------------------|
  | Shell     | Program interface to the OS  |
  | ~bash~ etc. | Shell scripting languages    |
  | eshell    | Emacs bash emulator          |
  | CMD line  | Windows term for the shell   |
  | Terminal  | MacOS term for the shell     |
  | tty       | Tele-type/session management |
  |           |                              |
  #+end_quote
* Things to do on the command line
#+attr_html: :width 500px
#+caption: Things to do on the command line (Source: Janssens, 2021)
[[../img/11_cmdline.png]]

- Example in a Linux docker container:
  #+attr_html: :width 500px
  #+caption: Command line terminal (bash) in a docker container
  [[../img/11_bash.png]]

- The command line is bigger than the shell:
  | CMD LINE TOOL      | EXAMPLE         |
  |--------------------+-----------------|
  | Binary executable  | ~bash --help~     |
  | Shell builtin      | ~cd .~            |
  | Interpreted script | ~hello.sh~        |
  | Shell function     | ~pwd~, ~date~, ~echo~   |
  | Alias              | ~alias~           |

* Why use the command line for data science
#+attr_html: :width 500px
#+caption: Huskies pulling sledge (State Lib of NSW on Flickr.com)
[[../img/11_huskies.jpg]]

1. Program to interact with the *operating system* (kernel) + memory
2. Sophisticated *script* language (~bash~, ~zsh~)
3. *REPL* (Read-Eval-Print-Loop) like ~replit.com~, ~Python~, ~R~, ~SQLite~[fn:2]
4. *Agile*, flexible and exploratory
5. *Augmenting* technology (glue to other applications)
   - Run pipeline (e.g. ~ls -a | wc -l~)
   - Run from inside your R program (with ~shell~)
   - Convert R code to command line script:
     #+begin_src sh :results output
       echo 'head(mtcars)' > t.R
       cat t.R
       Rscript t.R
     #+end_src
6. *Scalability*:
   - it's fast (sits right on top of the engine)
   - it is used to automate tasks
   - repeatable and parallelizable
7. *Extensibility*:
   - language agnostic
   - been in use for a long time
   - it is continuously improved
8. *Ubiquitous*: comes with all OS
9. *Cool factor* (you're "hacking")
10. *Relatable* (logical approach)

All of these are especially valuable in an exploratory environment
with highly distributed, unstructured, or "dirty" data sources.

* How to get a commandline for data science
#+attr_html: :width 500px
#+caption: Huskies pulling sledge (State Lib of NSW on Flickr.com)
[[../img/11_workspace.png]]

We're going to use DataCamp's workspaces - the Jupyter Notebook
installation, which is free for you, includes a suitably equipped
shell.

1. Logging into ~workspace.datacamp.com~ with your Lyon account
2. Picking a workspace template (empty, GitHub, data, project)
   - Upload GitHub [[https://github.com/birkenkrahe/py][repo]]
   - Choose SMS message data
   - Extraction with regex
   - Empty notebook "commandline"
3. Publishing a Jupyter notebook ~notebook.ipynb~
4. File management:
   - Upload ~.RData~ file
   - Load ~tm~ package
   - Print tweet no. 999 from ~clean_coffee~ corpus
5. Integrations with relational databases (pre-loaded)
   - For example ~employees~ - Add SQL block
   - Run ~SELECT 1+1~
   - Run ~SELECT COUNT(first_name) AS George from employees.employees
     WHERE first_name = "George" LIMIT 10;~
6. Check ~environment~: installed packages with versions
7. Select ~View~ > ~Switch to JupyterLab~ (vs. "DataCamp Notebook Editor")
8. Click ~+~ to get a ~Launcher~ tab:
   - R Notebook or R console or R file
   - ~bash~ terminal (~echo $SHELL~) which is where we will work!
9. Once created, the workspace is available any time with the link

* Your turn! Create your own commandline workspace

*How to do it:*
1) Go to ~workspace.datacamp.com~
2) Start from ~empty workspace~
3) Enter workspace name "commandline"
4) Choose Language: "R + SQL"
5) In the notebook go to "Launcher"
6) In ~notebook.ipynb~ type ~version~ and run it
7) In ~notebook.ipynb~ type ~plot(rnorm(1000))~ and run it
8) Open another window ("+" tab) and launch "Terminal"
9) In terminal, type ~cat /etc/os-release~
10) In terminal, type ~echo 'hello world'~
11) Open an R console, type ~plot(rnorm(1000))~ and run with ~<S-RET>~
12) Open an R script, enter ~plot(rnorm(1000))~ and name it ~plot.r~
13) Run script in the console with ~Rscript plot.r~
14) Test the built-in editor ~nano~:
    - write a script with ~head(mtcars)~ in ~nano~
    - save it as ~head.R~
    - check it with ~ls -l head.R~
    - view it with ~cat head.R~
    - run it with ~Rscript head.R~

More: [[https://support.datacamp.com/hc/en-us/articles/4680790331287-Getting-Started-with-DataCamp-Workspace][Getting Started with DataCamp Workspace]] (DataCamp 2023)

* Workspace picture gallery

- Create new empty workspace
  #+attr_latex: :width 400px
  #+caption: workspace creation
  [[../img/workspace1.png]]
- Run R command in Jupyter notebook cell
  #+attr_latex: :width 400px
  #+caption: Running an R command in a Jupyter Notebook cell
  [[../img/workspace2.png]]
- Run shell built-in function in the shell (REPL)
  #+attr_latex: :width 400px
  #+caption: Running a shell built-in function in the shell (REPL)
  [[../img/workspace3.png]]
- Running R code in the R console
  #+attr_latex: :width 400px
  #+caption: Running R code in the R console
  [[../img/workspace4.png]]
- Running R code as a batch job
  #+attr_latex: :width 400px
  #+caption: Output from running R code as a batch job
  [[../img/workspace5.png]]

* Alternative command line installations

*Victor says...*
- That you (with your student accounts) can just install the Windows
  Subsystem for Linux (WSL) from the Microsoft Store without admin
  rights.
- Please try it! Now!
- We're still going to use DataCamp workspaces (because it's a
  development environment rather than just a shel) but it's good to
  know that Linux is in reach!

*Alternatives:*
- Install a Docker container as described [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#how-to-set-up-a-docker-container-for-command-line-work][in this FAQ]] - there is also
  a short explanation what a "docker container" is [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#what-is-a-docker-container][in the FAQ]].
- Install the Ubuntu app using Windows Subsystem Linux (WSL) as
  [[https://github.com/birkenkrahe/org/blob/master/FAQ.org#how-can-i-install-linux-under-windows-10][described in this FAQ]].
- Get Linux as a dual boot or with (free) VirtualBox (any
  distro). [[https://www.howtogeek.com/796988/how-to-install-linux-in-virtualbox/][Instructions are here]]. Only for high-end laptops.
- Get a Linux computer ([[https://vilros.com/products/raspberry-pi-400-kit][like this one for $100]]) or brazenly and boldly
  just dump Windows for Linux and install it over Windows.
- Online/cloud installations like Google cloud shell, or replit.com,
  or the bundle of UNIX commands contained in ~cygwin~ do unfortunately
  not allow you to install the ~csvkit~ library, and exclude some other
  commands (like ~wget~).
- The Docker container already comes with ~cvskit~. Once you've got
  another Linux variant, install ~cvskit~ from the command line, e.g. in
  Debian-based systems (Raspberry Pi OS, Ubuntu) with the command ~sudo
  apt install csvkit~.

* Unix-type commands

- The following sections on ~curl~ and ~wget~ is based on the first
  chapter of the DataCamp course "Data processing in shell".

- Both commands obey the same Unix-type format:
  #+begin_example sh
    [command] [options/flags] [targets]
  #+end_example

- The specialty of Unix utilities are stable, small, fast routines
  each of which does one particular job really well and allow managing
  files, shell and text: e.g. ~ls~, ~ps~, ~cd~ - all of them written in C.

- The utilities attain full power only when used as part of a command
  pipeline, e.g. in the following codeblock:
  1) list files in ~$PWD~ in long format, time-ordered with ~ls~
  2) in the list, search for the pattern 'text' with ~grep~
  3) save the result of the search to a file ~files.txt~ with ~tee~
  4) count the characters of the search result with ~wc~
  #+begin_src sh
    ls -lt $PWD | grep text | tee files.txt | wc -c 
    cat 'files.txt'
  #+end_src

- The bulk of these utilities are part of the [[https://www.gnu.org/gnu/gnu.html][GNU Operating System]],
  which is FOSS. The GNU system also includes very large, complex
  programs like ~gcc~ and ~gdb~, the GNU compiler and debugger, or GNU
  Emacs, the self-extensible editor.

- Making these programs graphical does not add anything but only takes
  away transparency, speed of use, and performance - they embody the
  power of the command line.

- Jobs that cannot live without commandline tools include anything
  with data (at the engineering end), databases, networks or operating
  systems (including servers), especially (technical) cybersecurity.

* Download data with ~curl~

- Open your workspace on ~workspace.datacamp.com~ to try this yourself
  or run the commands in Emacs/Linux using my practice file[fn:3]

- The ~curl~ command line tool is short for "Client for URLs" and
  transports data to and from web servers.

- Check in the workspace if ~curl~ is installed (~/usr/bin/curl~):
  #+begin_example sh
    which curl
  #+end_example
  #+begin_example sh
    c:/Windows/system32/curl.exe
  #+end_example

* Getting to know a utility

- Your first step is to look at its option palette with ~--help~:
  #+begin_example sh
    curl --help
  #+end_example    

  #+begin_example sh
  $ Usage: curl [options...] <url>
   -d, --data <data>          HTTP POST data
   -f, --fail                 Fail fast with no output on HTTP errors
   -h, --help <category>      Get help for commands
   -i, --include              Include protocol response headers in the output
   -o, --output <file>        Write to file instead of stdout
   -O, --remote-name          Write output to a file named as the remote file
   -s, --silent               Silent mode
   -T, --upload-file <file>   Transfer local FILE to destination
   -u, --user <user:password> Server user and password
   -A, --user-agent <name>    Send User-Agent <name> to server
   -v, --verbose              Make the operation more talkative
   -V, --version              Show version number and quit

  This is not the full help, this menu is stripped into categories.
  Use "--help category" to get an overview of all categories.
  For all options use the manual or "--help all".
  #+end_example

- The help reveals that there are two sets of options/flags: a short
  version and a long, verbose version, e.g. ~-V~ and ~--version~:
  #+begin_example sh
    curl --version
  #+end_example
  #+begin_example org
  : curl 7.88.1 (x86_64-w64-mingw32) libcurl/7.88.1 OpenSSL/1.1.1t (Schannel) zlib/1.2.13 brotli/1.0.9 zstd/1.5.4 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.10.0 nghttp2/1.52.0
  : Release-Date: 2023-02-20
  : Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp
  : Features: alt-svc AsynchDNS brotli HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz MultiSSL NTLM PSL SPNEGO SSL SSPI threadsafe TLS-SRP UnixSockets zstd
  #+end_example

- This gives a lot of different information:
  1) version number and release date
  2) compiler and libraries used to create the binary (which is what
     you usually use under Windows, instead of building it from source
     under Linux)
  3) supported server protocols (everything under the sun)
  4) additional features to deal with network/data specifics

- Information on any shell utility is on its [[https://man7.org/linux/man-pages/man1/curl.1.html][manual page]] - on Linux,
  you can find these inside Emacs, too (~M-x man~).
  #+attr_latex: :width 400px
  #+caption: curl(7) man page
  [[../img/11_man_curl.png]]

* Examples for ~curl~

- Copy data from URL without changing name, then list file:
  #+begin_src sh
    pwd
    curl -O 'https://bit.ly/nile_txt'
    ls -l 'nile_txt'
  #+end_src
  #+begin_example org
  : /c/Users/birkenkrahe/Documents/GitHub/ds2/org
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:14 nile_txt
  #+end_example
- Copy data from URL, change name, then list files:
  #+begin_example sh
    pwd
    curl -o 'nile.txt' 'https://bit.ly/nile_txt'
    ls -l nile*
  #+end_example
  #+begin_example org
  : /c/Users/birkenkrahe/Documents/GitHub/ds2/org
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:16 nile.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 155 Apr  5 10:14 nile_txt
  #+end_example
- If you're tired (as I am) of typing ~ls -lt~, set an ~alias~:
  #+begin_example sh
    alias l='ls -lt'
  #+end_example
- Above, the 'wildcard' or 'glob' character ~*~ is actually a regular
  expression or a - more about these in the next lecture!

- The 'globbing parser' is a shell component that interprets and
  expands globs or wildcards. Here is an example with ~curl~:
  #+begin_example sh
    github=https://raw.githubusercontent.com/birkenkrahe/ds2/main
    curl --remote-name "$github/data/Nile[001-003].txt"
    ls -l Nile*
  #+end_example
  #+begin_example org
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile001.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile002.txt
  : -rw-r--r-- 1 Birkenkrahe 1049089 430 Apr  5 10:57 Nile003.txt
  #+end_example
- Explore other ~curl~ flags on your own time!

* Download data with ~wget~ - the background

- The utility ~wget~ is a "non-interactive" ("batch") network downloader
  that downloads very efficiently in the background from the Web.

- It is better than ~curl~ at downloading multiple files recursively
  (i.e. entering and copying nested file hierarchies), especially when
  connections are wonky - ~wget~ will just keep trying!

- Like other batch programs, ~wget~ also creates a log file ~wget-log~

- The notion of "background" relates to Unix' process management:
  e.g. I can put Emacs in the background (~C-z~) then check that the
  process is running (~ps -ax~) and bring it back into the foreground
  with ~fg~ - the image show this on a Linux shell:
  #+attr_latex: :width 400px
  #+caption: Emacs in the background
  [[../img/11_background.png]]

- This is the same thing that happens when we run an R script ~file.R~
  in "batch" mode with ~R CMD BATCH file.R~: the file is executed in the
  background and an ~.Rout~ log file is produced alongside the output:
  1) download ~$github/src/t.R~ with ~curl~ and name it ~mtcars.R~
  2) check that the file is there with ~ls~
  3) look at ~mtcars.R~ with ~cat~
  4) run ~mtcars.R~ as a batch script
  5) look at ~mtcars.Rout~
  #+begin_example sh
    github=https://raw.githubusercontent.com/birkenkrahe/ds2/main
    curl -o mtcars.R "$github/src/t.R"
    ls -l mtcars.R
    cat mtcars.R
    R CMD BATCH mtcars.R
    cat mtcars.Rout
  #+end_example

* Download examples with ~wget~

- Important flags:
  1) ~-b~ to go to background immediately after startup
  2) ~-q~ turn off output
  3) ~-c~ resume broken (partial) download
  4) ~-i~ pass a file with URLs to ~wget~ for download
  5) ~--limit-rate={rate}k~ set download constraint for large files
  6) ~--wait={seconds}~ pause between file downloads

- Use ~curl~ and ~wget~ in connection with a few other shell commands:
  1) define a variable ~spotify~ set to this URL (copy from chat):
     https://assets.datacamp.com/production/repositories/4180/datasets/eb1d6a36fa3039e4e00064797e1a1600d267b135/201812SpotifyData.zip
  2) check the variable with ~echo $spotify~
  3) download the ZIP file with ~curl -v -o spotify.zip $spotify~
  4) check download with ~l~ (aliased from ~ls -lt~ with ~alias~)
  5) extract data and remove ZIP file: ~unzip spotify.zip && rm spotify.zip~
  6) rename the CSV file with ~mv~ to ~spotify.csv~
  7) redirect the URL to a file: ~echo $spotify > url_list.txt~
  8) check content of file with ~cat url_list.txt~
  9) download the ZIP again: ~wget --limit-rate=2500k -i url_list.txt~
  10) show what you did with ~history~ and redo ~l~ with ~![id]~

- Whole exercise input with ~history~:   
  #+attr_latex: :width 400px
  [[../img/11_exercise.png]]

* ~curl~ vs ~wget~

| ~curl~                      | ~wget~                          |
|---------------------------+-------------------------------|
| good for single files     | handles bandwith problems     |
| many transfer protocols   | multiple file downloads       |
| easy to install across OS | handles multiple file formats |

* Summary
#+attr_latex: :width 400px
[[../img/certificate.png]]

- The command line (aka 'shell') is a programming and file management
  interface to the operating system.
- The shell offers a REPL, it is flexible, fast, exploratory,
  scalable, ubiquitous, and augmenting (plugs into other programs)
- To try shell programming and use get a Linux distribution e.g. as a
  docker image, or as a Linux subsystem (with Windows), or online as a
  cloud installation (like DataCamp workspace)
- For an easy & fun lesson on many useful shell commands, see
  ~Introduction to Shell~ at DataCamp. This takes no more than 2-4
  hours.

* Code glossary

| COMMAND   | MEANING                                       |
|-----------+-----------------------------------------------|
| ~ls~        | list files                                    |
| ~cd~        | change directory                              |
| ~ps~        | show processes                                |
| ~mv~        | move file                                     |
| ~echo~      | print argument to screen                      |
| ~echo $PWD~ | print present working directory               |
| ~/usr/bin~  | Linux directory for user's binary executables |
| ~curl~      | client URL download program                   |
| ~wget~      | program to get files from the web             |
| ~cat~       | view file                                     |
| ~>~         | redirect into file, e.g. ~echo "1"> file~       |
| ~>>~        | append to file                                |
| ~history~   | command history (call commands with ~!~)        |
| ~&&~        | (between commands) run together               |
| ~\vert~     | pipeline operator (LHS output = RHS input)    |
| ~alias~     | create command alias                          |
| ~&&~        | line up commands                              |
| ~chmod~     | change file permissions                       |
| ~;~         | (between commands) run after one another      |

* References

- Ballesteros (2006). Introduction to Operating Systems Abstractions:
  Using Plan 9 from Bell Labs (PDF). URL: [[http://doc.cat-v.org/plan_9/9.intro.pdf][doc.cat-v.org]].
- Gallant (2021). xsv. URL: [[https://github.com/BurntSushi/xsv][github.com]].
- Janssens (2021). Data science at the command line (2e). O'Reilly.

* Footnotes

[fn:3]If these commands work on the shell in Emacs or in ~sh~ code
blocks depends on the availability of the utilities on your PC and on
your ~PATH~ environment variable settings. Alternatively you can install
Ubuntu Linux as a Windows Linux Subsystem from the Microsoft store.

[fn:2]replit.com is a platform with multiple languages set up as
REPLs. Python (~M-x run-python~), R (~M-x R~) and SQLite (~M-x sql-sqlite~)
can be run interactively.

[fn:1]Here, ~plan9~ is the weirdest kid on the block: Plan 9 is file
server also known as the 9P protocol file server. It allows Windows to
access the files contained within WSL2. The name comes from a
distributed OS called Plan 9 (see Ballesteros, 2006).
