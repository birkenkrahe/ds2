{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Data science on the command line\n================================\n\n**Author:** Marcus Birkenkrahe\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## README\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![img](./wireservice.png \"Wireservice repo on GitHub\")\n\n-   Introduction to the `csvkit` toolkit (Python)\n-   Developed by wirekit for journalists\n-   Practice with Linux (DataCamp workspaces)\n-   Based on `csvkit` tutorial (different dataset)\n-   See also: Data Science at the Command Line ([Janssens, 2021](https://jeroenjanssens.com/dsatcl/)).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvkit` (Python)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   This demo is only interactive if you have access to a Linux\n    installation of some sort. Source: the `csvkit` [online tutorial](https://csvkit.readthedocs.io/en/latest/tutorial.html).\n\n-   In Spring 2023, we're going to use DataCamp's new workspace feature,\n    where you can install cvskit easily: `pip install csvkit`\n\n-   `csvskit` is a Python-3 library for manipulating text files.\n\n-   [I made a video of my whole demonstration in 2022](https://youtu.be/XhShmvBYNmw) (14 min) using the\n    dataset from the `csvkit` tutorial and a Linux docker container (same\n    software that DataCamp workspace uses for its terminal app).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install `csvkit`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Many of the `csvkit` functions are inspired by regular Unix commands.\n\n-   `pip` is a python-based package manager tool.\n    \n        pip install csvkit\n\n-   Or perhaps you already have all the `csv*` tools? The output should\n    show a bunch of different executables. `[dir]` is wherever your local\n    binary files are installed (`l` is a standard `alias` for `ls -alF` -\n    print long listing of all files with classification):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "l /usr/bin/*csv*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   In DataCamp, your installs are stored in `$HOME/.local/bin/`:\n    \n        l -t $HOME/.local/bin/*csv*\n\n-   If `pip` is missing, you can install it (shown for Debian-Linux):\n    \n        sudo apt install pip\n\n-   Or you may have to upgrade `pip` (the command line will tell you) -\n    but the upgrade will likely end up in your `.local` directory:\n    \n        python3 -mv pip install --upgrade pip\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's make a shell script\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Since we're getting kicked out of DataCamp workspace every 30\n    minutes, we want to put installations in a script:\n    \n        nano restart.sh\n\n-   This opens the `nano` editor where you can enter the following lines:\n    \n        #!/usr/bin/bash\n        pip --quiet install csvkit\n        ls --color $HOME/.local/bin/*csv*\n        PATH=$PATH:$HOME/.local/bin\n    \n    1.  run this shell file with `bash`\n    2.  install `csvkit` with `pip` (Python package manager)\n    3.  list contents of local `bin` directory with highlighting\n\n-   Save the file with `C-s` and exit with `C-x`.\n\n-   On the command line, change the file permissions to executable:\n    \n        chmod ugo+x restart.sh\n        ll restart.sh\n\n-   You can see that the file permissions are `-rwxr-xr-x` (executable for\n    user, group and others). The file listing color has changed and it\n    carries a `*`.\n\n-   Now run the file and redirect errors to the \"null device\", the void:\n    \n        . ./restart.sh 2>/dev/null\n\n-   You need to specify the location with `./` if your directory is not in\n    the `PATH`. The first `.` is the `source` command that exports local\n    variables (in this case the new `PATH`) to your current shell.\n\n-   Test if you can find the `csvkit` scripts:\n    \n        which in2csv\n\n-   You should get the location `/home/repl/.local/bin/csvstat`\n\n-   Any time you get kicked out of your workspace terminal, do:\n    \n        . ./restart.sh 2>/dev/null\n        cd csvkit\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting some data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  Make a new working directory `csvkit` with `mkdir`\n\n2.  Change into it with `cd`\n\n3.  Check where you are with `pwd`\n    \n        mkdir -v csvkit\n        cd csvkit\n        pwd\n\n4.  To save you from having to type long file names, I have put all\n    URLs in a shell script that you can download with `curl`: I will post\n    the URL in the Zoom chat!\n    \n        curl -o url.sh \"https://gist.githubusercontent.com/birkenkrahe/586db7e2ac26b09daa86769cca87002f/raw/54561f4c06f11157fed798d544901870e2137035/url.sh\"\n\n5.  Do the following on your own:\n    \n    1.  view the downloaded file with `cat`\n    2.  source the file with `.`\n    3.  check that the URLs are available with `echo`\n    \n        cat url.sh\n        . ./url.sh\n        echo $spotify && echo $coffee\n\n6.  Now download the corresponding files with `curl`:\n    \n        wget --quiet -O spotify.xlsx $spotify\n        wget --quiet -O coffee.xlsx $coffee\n\n7.  Check if the file `.xlsx` file is there - the `file` command gives\n    you some file type information, too:\n    \n        file coffee.xlsx\n        file spotify.xlsx\n\n8.  You can also try `curl` and `file` to get any old HTML file, like from Lyon:\n    \n        curl https://lyon.edu | tee fetched | head\n        file fetched\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The `csvkit` command suite\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `in2csv` converts tabular data files like Excel or text into CSV files\n-   `csvlook` prints CSV files in an easy-to-read format to the cmdline\n-   `csvstat` prints descriptive summary stats for each data type\n-   `csvcut`\n-   `csvgrep`\n-   `csvsort`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `in2csv` to re-write an Excel file as CSV file\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Excel is a binary format - you cannot look at it (without paying\n    Microsoft).\n\n-   `in2csv` rewrites the Excel file into CSV:\n    \n        in2csv coffee.xlsx > coffee.csv 2&>/dev/null\n        head -3 coffee.csv\n    \n    1.  `in2csv` runs the conversion on the following file\n    2.  `> coffee.csv` redirects the result to a file `coffee.csv`\n    3.  `2&>/dev/null` throws standard error messages away\n    4.  `head -3 coffee.csv` prints header and first two records\n\n-   More powerful with an Excel file that has worksheets:\n    \n        in2csv -n spotify.xlsx\n\n-   You can convert individual worksheets into CSV files:\n    \n        in2csv  spotify.xlsx --sheet \"Spotify_Popularity\" > pop.csv\n        head -5 pop.csv\n\n-   The term \"standard\" refers to the three available data streams:\n    standard error (stderr), output (stdout) and input (stdin).\n    \n    ![img](./std.png \"standard error, input and output\")\n\n-   In a pipeline, stdout is piped into stdin:\n    \n    ![img](./12_pipeline.png \"standard error, input and output\")\n\n-   The `rev` command reverses lines of its input:\n    \n        ls | rev  # reverses the characters of all file listings\n\n-   The `grep` command searches for patterns:\n    \n        ls | grep txt   # finds all files that contain 'txt'\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvlook` to get a table output of the CSV file\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `csvlook` provides a tabular look at the data.\n    \n        csvlook pop.csv\n        csvlook --max-rows 5 coffee.csv\n\n-   Look at the help for `csvlook` and limit the output of `coffee.csv` to 5\n    columns:\n    \n        csvlook --max-columns 5 --max-rows 5 coffee.csv\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvstat` for summary statistics\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `csvstat` is inspired by R's `summary` function\n    \n        csvstat pop.csv\n\n-   Alternativesly as a pipeline:\n    \n        cat data1.csv | csvstat\n\n-   For more interesting stats, turn the other sheet in `spotify.xlsx`\n    into a CSV file `music.csv` and print the stats:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "in2csv -n \nin2csv spotify.xlsx --sheet \"Spotify_MusicAttributes\" > music.csv\ncsvstats music.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvcut` to filter by row\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `csvcut` is a version of `cut` for `CSV` files\n    \n    1.  the `-n` option shows all columns\n    2.  the `-c` option shows specific columns\n    \n        csvcut -n coffee.csv\n        csvcut -c 2,5,6 music.csv| head -5\n\n-   Look at the columns of `music.csv` and `coffee.csv` :\n    \n        csvcut -n music.csv\n        csvcut -n coffee.csv\n\n-   Look at the first five records of the columns 1,3 of `coffee.csv` and\n    the columns 2,5,6 of `music.csv`:\n    \n        csvcut -c 1,3 coffee.csv | head -5\n        csvcut -c 2,5,6 music.csv | head -5\n\n-   Output columns can be called by name, too - here, the pipe prints\n    tabular format (`csvlook`) and the first 5 records only:\n    \n        csvcut -c county,item_name,quantity data.csv | csvlook | head -5\n\n-   Apply the example to `music.csv` and three of its columns by name:\n    \n        csvcut -n music.csv\n        csvcut -c track_id,loudness,tempo | csvlook | head -5\n\n-   Did you get an error? Could you fix it?\n\n>     `csvcut` does not ignore whitespace between the arguments to its\n>     flags, so `-c tempo, loudness` throws an error, but `-c\n>     tempo,loudness` does not.\n\n-   I want to use some of the output later so I put it into a file:\n    \n        csvcut -c danceability,time_signature music.csv |\n           tee cols.csv |\n           csvlook |\n           head -5\n\n-   All of the previous operations can be put together in one pipe:\n    \n        in2csv coffee.xlsx |\n        csvcut -c num,text |\n        tee coffee |\n        csvlook |\n        head -3\n\n-   How many lines does `coffee` have?\n    \n        cat coffee | wc -l\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvgrep` to filter by row\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `csvgrep` is a pattern-matching search function.\n    \n    -   run `csvgrep` on the `data1.csv` subset\n    -   focus on the `county` column with `-c`\n    -   match the pattern `LANCASTER` county\n    -   look at the result as a table\n    \n        csvgrep -c county -m LANCASTER data1.csv | csvlook\n    \n    -   count the lines (= entries for LANCASTER county)\n    \n        csvgrep -c county -m LANCASTER data1.csv | wc -l\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `csvsort` to sort rows by column\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `csvsort` sorts the rows by any column (or combination of columns)\n    in ascending or descending (reverse) order.\n    \n        csvcut -c county,item_name,total_cost data.csv > data2.csv\n        cat data2.csv | csvgrep -c county -m LANCASTER > data3.csv\n        cat data3.csv | csvsort -c total_cost -r | csvlook\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Janssens (2021). Data science at the command line\n    (2e). O'Reilly. URL: [jeroenjanssens.com](https://jeroenjanssens.com/dsatcl/).\n\n"
      ]
    }
  ],
  "metadata": [
    [
      "org"
    ],
    null,
    null
  ],
  "nbformat": 4,
  "nbformat_minor": 0
}